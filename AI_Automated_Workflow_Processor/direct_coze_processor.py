#!/usr/bin/env python3
"""
ç›´æ¥å¤„ç†Cozeå·¥ä½œæµURLï¼ŒåŒ…å«å®Œæ•´çš„AIWorkflowProcessoråŠŸèƒ½
"""

import json
import requests
import re
import os
import time
from typing import Dict, List, Any, Optional, Tuple

class AIWorkflowProcessor:
    """AIè‡ªåŠ¨åŒ–å·¥ä½œæµå¤„ç†å™¨æ ¸å¿ƒç±»"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–å·¥ä½œæµå¤„ç†å™¨
        
        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«APIå¯†é’¥ã€æ¨¡å‹é…ç½®ç­‰
        """
        self.config = self._load_config(config)
        self.supported_workflow_formats = ["json", "yaml", "yml"]
        self.workflow_schema = self._load_workflow_schema()
    
    def _load_config(self, config: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """åŠ è½½é…ç½®
        
        Args:
            config: å¤–éƒ¨é…ç½®
            
        Returns:
            åˆå¹¶åçš„é…ç½®å­—å…¸
        """
        default_config = {
            "deepseek_api_key": "",
            "deepseek_api_url": "https://api.deepseek.com",
            "model": "deepseek-chat",
            "timeout": 60,
            "output_dir": "./workflow_output",
            "log_level": "info"
        }
        
        if config:
            default_config.update(config)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(default_config["output_dir"], exist_ok=True)
        
        return default_config
    
    def _load_workflow_schema(self) -> Dict[str, Any]:
        """åŠ è½½å·¥ä½œæµschema
        
        Returns:
            å·¥ä½œæµschemaå­—å…¸
        """
        # ç®€åŒ–çš„å·¥ä½œæµschemaï¼Œå®é™…é¡¹ç›®ä¸­å¯ä»¥ä»æ–‡ä»¶æˆ–APIåŠ è½½
        return {
            "type": "object",
            "required": ["name", "description", "nodes", "edges"],
            "properties": {
                "name": {"type": "string"},
                "description": {"type": "string"},
                "version": {"type": "string"},
                "nodes": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "required": ["id", "type", "data"],
                        "properties": {
                            "id": {"type": "string"},
                            "type": {"type": "string"},
                            "data": {"type": "object"},
                            "position": {"type": "object"}
                        }
                    }
                },
                "edges": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "required": ["id", "source", "target"],
                        "properties": {
                            "id": {"type": "string"},
                            "source": {"type": "string"},
                            "target": {"type": "string"},
                            "sourceHandle": {"type": "string"},
                            "targetHandle": {"type": "string"}
                        }
                    }
                }
            }
        }
    
    def get_resource_from_url(self, url: str) -> Dict[str, Any]:
        """ä»URLè·å–èµ„æº
        
        Args:
            url: èµ„æºURL
            
        Returns:
            èµ„æºå†…å®¹å­—å…¸
        """
        try:
            response = requests.get(url, timeout=self.config["timeout"])
            response.raise_for_status()
            return {
                "status": "success",
                "data": response.json(),
                "message": f"Successfully fetched resource from {url}"
            }
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "message": f"Failed to fetch resource from {url}"
            }
    
    def detect_workflow_errors(self, workflow: Dict[str, Any]) -> Dict[str, Any]:
        """æ£€æµ‹å·¥ä½œæµé”™è¯¯
        
        Args:
            workflow: å·¥ä½œæµæ•°æ®
            
        Returns:
            é”™è¯¯æ£€æµ‹ç»“æœ
        """
        errors = []
        warnings = []
        
        # æ£€æŸ¥å¿…å¡«å­—æ®µ
        required_fields = self.workflow_schema.get("required", [])
        for field in required_fields:
            if field not in workflow:
                errors.append({
                    "type": "missing_required_field",
                    "field": field,
                    "message": f"Missing required field: {field}"
                })
        
        # æ£€æŸ¥èŠ‚ç‚¹
        if "nodes" in workflow:
            nodes = workflow["nodes"]
            node_ids = set()
            
            for i, node in enumerate(nodes):
                # æ£€æŸ¥èŠ‚ç‚¹å¿…å¡«å­—æ®µ
                node_required = self.workflow_schema["properties"]["nodes"]["items"]["required"]
                for field in node_required:
                    if field not in node:
                        errors.append({
                            "type": "missing_node_field",
                            "node_index": i,
                            "field": field,
                            "message": f"Node {i} missing required field: {field}"
                        })
                
                # æ£€æŸ¥èŠ‚ç‚¹IDå”¯ä¸€æ€§
                if "id" in node:
                    if node["id"] in node_ids:
                        errors.append({
                            "type": "duplicate_node_id",
                            "node_id": node["id"],
                            "message": f"Duplicate node ID: {node['id']}"
                        })
                    node_ids.add(node["id"])
        
        # æ£€æŸ¥è¾¹
        if "edges" in workflow:
            edges = workflow["edges"]
            edge_ids = set()
            
            for i, edge in enumerate(edges):
                # æ£€æŸ¥è¾¹å¿…å¡«å­—æ®µ
                edge_required = self.workflow_schema["properties"]["edges"]["items"]["required"]
                for field in edge_required:
                    if field not in edge:
                        errors.append({
                            "type": "missing_edge_field",
                            "edge_index": i,
                            "field": field,
                            "message": f"Edge {i} missing required field: {field}"
                        })
                
                # æ£€æŸ¥è¾¹IDå”¯ä¸€æ€§
                if "id" in edge:
                    if edge["id"] in edge_ids:
                        errors.append({
                            "type": "duplicate_edge_id",
                            "edge_id": edge["id"],
                            "message": f"Duplicate edge ID: {edge['id']}"
                        })
                    edge_ids.add(edge["id"])
                
                # æ£€æŸ¥è¾¹å¼•ç”¨çš„èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨
                if "source" in edge and "target" in edge and "nodes" in workflow:
                    node_ids = {node["id"] for node in workflow["nodes"]}
                    if edge["source"] not in node_ids:
                        errors.append({
                            "type": "invalid_edge_source",
                            "edge_id": edge.get("id", f"edge_{i}"),
                            "source": edge["source"],
                            "message": f"Edge references non-existent source node: {edge['source']}"
                        })
                    if edge["target"] not in node_ids:
                        errors.append({
                            "type": "invalid_edge_target",
                            "edge_id": edge.get("id", f"edge_{i}"),
                            "target": edge["target"],
                            "message": f"Edge references non-existent target node: {edge['target']}"
                        })
        
        return {
            "status": "success",
            "errors": errors,
            "warnings": warnings,
            "total_errors": len(errors),
            "total_warnings": len(warnings)
        }
    
    def fix_workflow_errors(self, workflow: Dict[str, Any], error_report: Dict[str, Any]) -> Dict[str, Any]:
        """ä¿®å¤å·¥ä½œæµé”™è¯¯
        
        Args:
            workflow: å·¥ä½œæµæ•°æ®
            error_report: é”™è¯¯æ£€æµ‹æŠ¥å‘Š
            
        Returns:
            ä¿®å¤åçš„å·¥ä½œæµå’Œä¿®å¤æŠ¥å‘Š
        """
        fixed_workflow = workflow.copy()
        fixes = []
        
        # ä¿®å¤ç¼ºå¤±çš„å¿…å¡«å­—æ®µ
        required_fields = self.workflow_schema.get("required", [])
        for field in required_fields:
            if field not in fixed_workflow:
                if field == "name":
                    fixed_workflow["name"] = "Untitled Workflow"
                    fixes.append({
                        "type": "added_required_field",
                        "field": field,
                        "value": fixed_workflow[field],
                        "message": f"Added missing required field '{field}' with default value"
                    })
                elif field == "description":
                    fixed_workflow["description"] = "Automatically generated workflow"
                    fixes.append({
                        "type": "added_required_field",
                        "field": field,
                        "value": fixed_workflow[field],
                        "message": f"Added missing required field '{field}' with default value"
                    })
                elif field == "nodes":
                    fixed_workflow["nodes"] = []
                    fixes.append({
                        "type": "added_required_field",
                        "field": field,
                        "value": fixed_workflow[field],
                        "message": f"Added missing required field '{field}' with empty array"
                    })
                elif field == "edges":
                    fixed_workflow["edges"] = []
                    fixes.append({
                        "type": "added_required_field",
                        "field": field,
                        "value": fixed_workflow[field],
                        "message": f"Added missing required field '{field}' with empty array"
                    })
        
        # ä¿®å¤èŠ‚ç‚¹é—®é¢˜
        if "nodes" in fixed_workflow:
            nodes = fixed_workflow["nodes"]
            node_ids = set()
            
            for i, node in enumerate(nodes):
                # ç¡®ä¿èŠ‚ç‚¹IDå”¯ä¸€
                if "id" in node:
                    original_id = node["id"]
                    counter = 1
                    while node["id"] in node_ids:
                        node["id"] = f"{original_id}_{counter}"
                        counter += 1
                    if node["id"] != original_id:
                        fixes.append({
                            "type": "fixed_duplicate_node_id",
                            "node_index": i,
                            "old_id": original_id,
                            "new_id": node["id"],
                            "message": f"Fixed duplicate node ID: {original_id} -> {node['id']}"
                        })
                    node_ids.add(node["id"])
                else:
                    # æ·»åŠ ç¼ºå¤±çš„èŠ‚ç‚¹ID
                    new_id = f"node_{i}"
                    node["id"] = new_id
                    node_ids.add(new_id)
                    fixes.append({
                        "type": "added_node_id",
                        "node_index": i,
                        "new_id": new_id,
                        "message": f"Added missing node ID: {new_id}"
                    })
        
        # ä¿®å¤è¾¹é—®é¢˜
        if "edges" in fixed_workflow and "nodes" in fixed_workflow:
            edges = fixed_workflow["edges"]
            edge_ids = set()
            node_ids = {node["id"] for node in fixed_workflow["nodes"]}
            
            for i, edge in enumerate(edges):
                # ç¡®ä¿è¾¹IDå”¯ä¸€
                if "id" in edge:
                    original_id = edge["id"]
                    counter = 1
                    while edge["id"] in edge_ids:
                        edge["id"] = f"{original_id}_{counter}"
                        counter += 1
                    if edge["id"] != original_id:
                        fixes.append({
                            "type": "fixed_duplicate_edge_id",
                            "edge_index": i,
                            "old_id": original_id,
                            "new_id": edge["id"],
                            "message": f"Fixed duplicate edge ID: {original_id} -> {edge['id']}"
                        })
                    edge_ids.add(edge["id"])
                else:
                    # æ·»åŠ ç¼ºå¤±çš„è¾¹ID
                    new_id = f"edge_{i}"
                    edge["id"] = new_id
                    edge_ids.add(new_id)
                    fixes.append({
                        "type": "added_edge_id",
                        "edge_index": i,
                        "new_id": new_id,
                        "message": f"Added missing edge ID: {new_id}"
                    })
        
        return {
            "status": "success",
            "fixed_workflow": fixed_workflow,
            "fixes": fixes,
            "total_fixes": len(fixes)
        }
    
    def analyze_code_quality(self, code: str, language: str = "python") -> Dict[str, Any]:
        """åˆ†æä»£ç è´¨é‡
        
        Args:
            code: ä»£ç å†…å®¹
            language: ä»£ç è¯­è¨€
            
        Returns:
            ä»£ç è´¨é‡åˆ†ææŠ¥å‘Š
        """
        # ç®€åŒ–çš„ä»£ç è´¨é‡åˆ†æï¼Œå®é™…é¡¹ç›®ä¸­å¯ä»¥é›†æˆæ›´å¤æ‚çš„åˆ†æå·¥å…·
        issues = []
        
        # æ£€æŸ¥ä»£ç è¡Œæ•°
        lines = code.split('\n')
        total_lines = len(lines)
        
        # æ£€æŸ¥ç©ºè¡Œ
        empty_lines = sum(1 for line in lines if line.strip() == '')
        
        # æ£€æŸ¥æ³¨é‡Šæ¯”ä¾‹
        comment_lines = sum(1 for line in lines if line.strip().startswith('#') or '#' in line)
        comment_ratio = comment_lines / total_lines if total_lines > 0 else 0
        
        # æ£€æŸ¥é•¿è¡Œ
        long_lines = [i+1 for i, line in enumerate(lines) if len(line) > 80]
        for line_num in long_lines:
            issues.append({
                "type": "long_line",
                "line": line_num,
                "message": f"Line {line_num} is too long (exceeds 80 characters)"
            })
        
        # æ£€æŸ¥é‡å¤ä»£ç ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        line_counts = {}
        for line in lines:
            stripped = line.strip()
            if stripped and not stripped.startswith('#'):
                line_counts[stripped] = line_counts.get(stripped, 0) + 1
        
        for line, count in line_counts.items():
            if count > 5:
                issues.append({
                    "type": "repeated_code",
                    "line_content": line,
                    "count": count,
                    "message": f"Code line repeated {count} times: {line}"
                })
        
        # æ£€æŸ¥ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²
        if language == "python":
            # ç®€å•æ£€æŸ¥å‡½æ•°ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²
            function_pattern = r'def\s+\w+\s*\([^)]*\)\s*:'
            functions = re.finditer(function_pattern, code)
            
            for match in functions:
                function_start = match.end()
                # æ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦æ˜¯æ–‡æ¡£å­—ç¬¦ä¸²
                next_line = code[function_start:].split('\n')[0].strip()
                if not (next_line.startswith('"""') or next_line.startswith("'""")):
                    issues.append({
                        "type": "missing_docstring",
                        "function": match.group(),
                        "message": f"Function {match.group()} missing docstring"
                    })
        
        return {
            "status": "success",
            "language": language,
            "total_lines": total_lines,
            "empty_lines": empty_lines,
            "comment_lines": comment_lines,
            "comment_ratio": round(comment_ratio, 2),
            "issues": issues,
            "total_issues": len(issues)
        }
    
    def generate_workflow(self, requirements: str) -> Dict[str, Any]:
        """æ ¹æ®éœ€æ±‚ç”Ÿæˆå·¥ä½œæµ
        
        Args:
            requirements: å·¥ä½œæµéœ€æ±‚æè¿°
            
        Returns:
            ç”Ÿæˆçš„å·¥ä½œæµ
        """
        # ç®€åŒ–çš„å·¥ä½œæµç”Ÿæˆï¼Œå®é™…é¡¹ç›®ä¸­å¯ä»¥é›†æˆLLMæ¥ç”Ÿæˆæ›´å¤æ‚çš„å·¥ä½œæµ
        workflow = {
            "name": "Generated Workflow",
            "description": f"Automatically generated from requirements: {requirements}",
            "version": "1.0.0",
            "nodes": [
                {
                    "id": "start",
                    "type": "start",
                    "data": {
                        "label": "Start",
                        "description": "Workflow start node"
                    },
                    "position": {"x": 100, "y": 100}
                },
                {
                    "id": "process",
                    "type": "process",
                    "data": {
                        "label": "Process",
                        "description": "Main processing node",
                        "requirements": requirements
                    },
                    "position": {"x": 300, "y": 100}
                },
                {
                    "id": "end",
                    "type": "end",
                    "data": {
                        "label": "End",
                        "description": "Workflow end node"
                    },
                    "position": {"x": 500, "y": 100}
                }
            ],
            "edges": [
                {
                    "id": "edge_start_process",
                    "source": "start",
                    "target": "process"
                },
                {
                    "id": "edge_process_end",
                    "source": "process",
                    "target": "end"
                }
            ]
        }
        
        return {
            "status": "success",
            "workflow": workflow,
            "requirements": requirements
        }
    
    def auto_fill_canvas(self, workflow: Dict[str, Any]) -> Dict[str, Any]:
        """è‡ªåŠ¨åŒ–å¡«å†™Cozeç”»å¸ƒ
        
        Args:
            workflow: å·¥ä½œæµæ•°æ®
            
        Returns:
            å¡«å†™å®Œæˆçš„ç”»å¸ƒæ•°æ®
        """
        # ç®€åŒ–çš„ç”»å¸ƒå¡«å†™ï¼Œå®é™…é¡¹ç›®ä¸­éœ€è¦æ ¹æ®Cozeç”»å¸ƒçš„å…·ä½“æ ¼å¼è¿›è¡Œå¡«å†™
        canvas_data = {
            "workflow": workflow,
            "canvas_settings": {
                "title": workflow.get("name", "Untitled Canvas"),
                "description": workflow.get("description", ""),
                "version": workflow.get("version", "1.0.0"),
                "theme": "default",
                "zoom": 1.0,
                "centerX": 0,
                "centerY": 0
            },
            "nodes_positioned": True,
            "auto_layout": True
        }
        
        # è‡ªåŠ¨å¸ƒå±€èŠ‚ç‚¹ï¼ˆç®€åŒ–ç‰ˆï¼‰
        if "nodes" in workflow:
            nodes = workflow["nodes"]
            for i, node in enumerate(nodes):
                if "position" not in node:
                    node["position"] = {
                        "x": 100 + (i * 200),
                        "y": 100
                    }
        
        return {
            "status": "success",
            "canvas_data": canvas_data,
            "message": "Canvas automatically filled"
        }

# Cozeå·¥ä½œæµURL
COZE_WORKFLOW_URL = "https://www.coze.cn/work_flow?space_id=7382283479335403547&workflow_id=7582809614418624547&force_stay=1"

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å¤„ç†Cozeå·¥ä½œæµ")
    print(f"ğŸ“¡ å·¥ä½œæµURL: {COZE_WORKFLOW_URL}")
    
    # åˆå§‹åŒ–å·¥ä½œæµå¤„ç†å™¨
    processor = AIWorkflowProcessor()
    
    # ä»URLè·å–å·¥ä½œæµæ•°æ®
    print("\n1. ä»URLè·å–å·¥ä½œæµæ•°æ®...")
    fetch_result = processor.get_resource_from_url(COZE_WORKFLOW_URL)
    
    if fetch_result["status"] == "success":
        print(f"âœ… æˆåŠŸè·å–å·¥ä½œæµæ•°æ®")
        
        # ä¿å­˜åŸå§‹å·¥ä½œæµæ•°æ®
        with open("original_coze_workflow.json", "w", encoding="utf-8") as f:
            json.dump(fetch_result["data"], f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ åŸå§‹å·¥ä½œæµæ•°æ®å·²ä¿å­˜åˆ°: original_coze_workflow.json")
        
        # æ£€æµ‹å·¥ä½œæµé”™è¯¯
        print("\n2. æ£€æµ‹å·¥ä½œæµé”™è¯¯...")
        error_result = processor.detect_workflow_errors(fetch_result["data"])
        
        print(f"ğŸ“‹ é”™è¯¯æ£€æµ‹ç»“æœ:")
        print(f"   é”™è¯¯æ•°é‡: {error_result['total_errors']}")
        print(f"   è­¦å‘Šæ•°é‡: {error_result['total_warnings']}")
        
        # ä¿å­˜é”™è¯¯æ£€æµ‹ç»“æœ
        with open("workflow_error_report.json", "w", encoding="utf-8") as f:
            json.dump(error_result, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ é”™è¯¯æ£€æµ‹æŠ¥å‘Šå·²ä¿å­˜åˆ°: workflow_error_report.json")
        
        # å¦‚æœæœ‰é”™è¯¯ï¼Œä¿®å¤å·¥ä½œæµ
        if error_result["total_errors"] > 0:
            print("\n3. ä¿®å¤å·¥ä½œæµé”™è¯¯...")
            fix_result = processor.fix_workflow_errors(fetch_result["data"], error_result)
            
            print(f"ğŸ“‹ å·¥ä½œæµä¿®å¤ç»“æœ:")
            print(f"   ä¿®å¤æ•°é‡: {fix_result['total_fixes']}")
            print(f"   ä¿®å¤åæ˜¯å¦åŒ…å«edgeså­—æ®µ: {'edges' in fix_result['fixed_workflow']}")
            
            # ä¿å­˜ä¿®å¤åçš„å·¥ä½œæµ
            with open("repaired_coze_workflow.json", "w", encoding="utf-8") as f:
                json.dump(fix_result["fixed_workflow"], f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ä¿®å¤åçš„å·¥ä½œæµå·²ä¿å­˜åˆ°: repaired_coze_workflow.json")
            
            # ä¿å­˜ä¿®å¤æŠ¥å‘Š
            with open("workflow_fix_report.json", "w", encoding="utf-8") as f:
                json.dump(fix_result, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ å·¥ä½œæµä¿®å¤æŠ¥å‘Šå·²ä¿å­˜åˆ°: workflow_fix_report.json")
        
        # è‡ªåŠ¨å¡«å†™ç”»å¸ƒ
        print("\n4. è‡ªåŠ¨å¡«å†™Cozeç”»å¸ƒ...")
        canvas_result = processor.auto_fill_canvas(fetch_result["data"])
        
        # ä¿å­˜ç”»å¸ƒæ•°æ®
        with open("auto_filled_canvas.json", "w", encoding="utf-8") as f:
            json.dump(canvas_result["canvas_data"], f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ è‡ªåŠ¨å¡«å†™çš„ç”»å¸ƒæ•°æ®å·²ä¿å­˜åˆ°: auto_filled_canvas.json")
        
        print("\nğŸ‰ Cozeå·¥ä½œæµå¤„ç†å®Œæˆï¼")
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print("   - original_coze_workflow.json: åŸå§‹å·¥ä½œæµæ•°æ®")
        print("   - workflow_error_report.json: é”™è¯¯æ£€æµ‹æŠ¥å‘Š")
        if error_result["total_errors"] > 0:
            print("   - repaired_coze_workflow.json: ä¿®å¤åçš„å·¥ä½œæµ")
            print("   - workflow_fix_report.json: å·¥ä½œæµä¿®å¤æŠ¥å‘Š")
        print("   - auto_filled_canvas.json: è‡ªåŠ¨å¡«å†™çš„ç”»å¸ƒæ•°æ®")
        
    else:
        print(f"âŒ ä»URLè·å–å·¥ä½œæµæ•°æ®å¤±è´¥: {fetch_result['error']}")
        print(f"â„¹ï¸  å¯èƒ½éœ€è¦ç™»å½•Cozeè´¦å·æ‰èƒ½è®¿é—®å·¥ä½œæµæ•°æ®")
        print(f"ğŸ’¡ å»ºè®®: æ‰‹åŠ¨ç™»å½•Cozeè´¦å·ï¼Œå¯¼å‡ºå·¥ä½œæµJSONæ–‡ä»¶ï¼Œç„¶åä½¿ç”¨AIè‡ªåŠ¨åŒ–å·¥ä½œæµå¤„ç†å™¨å¤„ç†")


if __name__ == "__main__":
    main()
