{
  "version": "2.0",
  "name": "ç»ˆæå¢é‡æ‰¹é‡è‡ªåŠ¨åŒ–Cozeå·¥ä½œæµç³»ç»Ÿ",
  "description": "åŸºäºDeepSeekè®¾è®¡çš„å®Œæ•´å¢é‡æ‰¹é‡è‡ªåŠ¨åŒ–Cozeå·¥ä½œæµï¼Œæ”¯æŒå¤šå­˜å‚¨å¹³å°ã€æ·±å±‚ä¿®å¤ã€è‡ªåŠ¨åŒ–ç”Ÿæˆç­‰é«˜çº§åŠŸèƒ½",
  "trigger": {
    "type": "mixed",
    "config": {
      "schedules": [
        {
          "name": "æ¯æ—¥å…¨é‡å¤„ç†",
          "cron": "0 2 * * *",
          "enabled": true,
          "description": "æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œå…¨é‡æ•°æ®å¤„ç†"
        },
        {
          "name": "æ¯å°æ—¶å¢é‡æ£€æŸ¥",
          "cron": "0 * * * *",
          "enabled": true,
          "description": "æ¯å°æ—¶æ£€æŸ¥æ–°æ•°æ®"
        },
        {
          "name": "å®æ—¶ç›‘æ§",
          "cron": "*/15 * * * *",
          "enabled": false,
          "description": "æ¯15åˆ†é’Ÿç›‘æ§ä¸€æ¬¡ï¼ˆå¯é€‰ï¼‰"
        }
      ],
      "webhook": {
        "endpoint": "/api/webhook/ultimate-workflow",
        "method": "POST",
        "secret": "{{env.WEBHOOK_SECRET}}",
        "rate_limit": 100,
        "timeout": 30000
      },
      "manual": {
        "enabled": true,
        "description": "æ”¯æŒæ‰‹åŠ¨è§¦å‘æ‰§è¡Œ"
      },
      "event_driven": {
        "enabled": true,
        "events": ["data_change", "api_update", "file_upload"]
      }
    }
  },
  "environment_variables": [
    {
      "name": "STORAGE_TYPE",
      "type": "string",
      "required": false,
      "default": "github",
      "description": "å­˜å‚¨ç±»å‹ï¼šgithub, supabase, local_pg, hybrid"
    },
    {
      "name": "GITHUB_TOKEN",
      "type": "secret",
      "required": false,
      "description": "GitHub Personal Access Token"
    },
    {
      "name": "GITHUB_REPO",
      "type": "string",
      "required": false,
      "description": "GitHubä»“åº“è·¯å¾„ï¼Œæ ¼å¼ï¼šç”¨æˆ·å/ä»“åº“å"
    },
    {
      "name": "SUPABASE_URL",
      "type": "string",
      "required": false,
      "description": "Supabaseé¡¹ç›®URL"
    },
    {
      "name": "SUPABASE_KEY",
      "type": "secret",
      "required": false,
      "description": "Supabase anon key"
    },
    {
      "name": "LOCAL_PG_HOST",
      "type": "string",
      "required": false,
      "default": "localhost",
      "description": "æœ¬åœ°PostgreSQLä¸»æœºåœ°å€"
    },
    {
      "name": "LOCAL_PG_PORT",
      "type": "number",
      "required": false,
      "default": 5432,
      "description": "æœ¬åœ°PostgreSQLç«¯å£"
    },
    {
      "name": "LOCAL_PG_DATABASE",
      "type": "string",
      "required": false,
      "default": "postgres",
      "description": "æœ¬åœ°PostgreSQLæ•°æ®åº“åç§°"
    },
    {
      "name": "LOCAL_PG_USER",
      "type": "string",
      "required": false,
      "default": "postgres",
      "description": "æœ¬åœ°PostgreSQLç”¨æˆ·å"
    },
    {
      "name": "LOCAL_PG_PASSWORD",
      "type": "secret",
      "required": false,
      "description": "æœ¬åœ°PostgreSQLå¯†ç "
    },
    {
      "name": "BATCH_SIZE",
      "type": "number",
      "required": false,
      "default": 100,
      "description": "æ‰¹é‡å¤„ç†å¤§å°"
    },
    {
      "name": "MAX_CONCURRENT",
      "type": "number",
      "required": false,
      "default": 5,
      "description": "æœ€å¤§å¹¶å‘æ•°"
    },
    {
      "name": "RETRY_COUNT",
      "type": "number",
      "required": false,
      "default": 3,
      "description": "é‡è¯•æ¬¡æ•°"
    },
    {
      "name": "RETRY_DELAY",
      "type": "number",
      "required": false,
      "default": 5000,
      "description": "é‡è¯•å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰"
    },
    {
      "name": "TIMEOUT_SECONDS",
      "type": "number",
      "required": false,
      "default": 300,
      "description": "è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰"
    },
    {
      "name": "ENABLE_DEEP_REPAIR",
      "type": "boolean",
      "required": false,
      "default": true,
      "description": "å¯ç”¨æ·±å±‚ä¿®å¤åŠŸèƒ½"
    },
    {
      "name": "ENABLE_AUTO_GENERATION",
      "type": "boolean",
      "required": false,
      "default": true,
      "description": "å¯ç”¨è‡ªåŠ¨åŒ–ç”ŸæˆåŠŸèƒ½"
    },
    {
      "name": "ENABLE_BATCH_PROCESSING",
      "type": "boolean",
      "required": false,
      "default": true,
      "description": "å¯ç”¨æ‰¹é‡å¤„ç†åŠŸèƒ½"
    },
    {
      "name": "DATA_SOURCES",
      "type": "json",
      "required": false,
      "default": "[{\"type\":\"api\",\"config\":{\"url\":\"https://api.example.com/data\"}}]",
      "description": "æ•°æ®æºé…ç½®"
    },
    {
      "name": "STORAGE_CONFIG",
      "type": "json",
      "required": false,
      "default": "{\"type\":\"github\",\"table\":\"processed_data\"}",
      "description": "å­˜å‚¨é…ç½®"
    },
    {
      "name": "NOTIFICATION_CONFIG",
      "type": "json",
      "required": false,
      "default": "{\"types\":[\"github_issue\"]}",
      "description": "é€šçŸ¥é…ç½®"
    },
    {
      "name": "WORKFLOW_TEMPLATES",
      "type": "json",
      "required": false,
      "default": "{}",
      "description": "å·¥ä½œæµæ¨¡æ¿é…ç½®"
    },
    {
      "name": "ERROR_WEBHOOK",
      "type": "string",
      "required": false,
      "description": "é”™è¯¯é€šçŸ¥Webhook URL"
    },
    {
      "name": "MONITORING_ENDPOINT",
      "type": "string",
      "required": false,
      "description": "ç›‘æ§ç«¯ç‚¹URL"
    },
    {
      "name": "LOG_LEVEL",
      "type": "string",
      "required": false,
      "default": "info",
      "description": "æ—¥å¿—çº§åˆ«ï¼šdebug, info, warn, error"
    }
  ],
  "nodes": [
    {
      "id": "1",
      "name": "ğŸš€ ç³»ç»Ÿåˆå§‹åŒ–ä¸é…ç½®éªŒè¯",
      "type": "javascript",
      "description": "å®Œæ•´çš„ç³»ç»Ÿåˆå§‹åŒ–ï¼ŒåŒ…æ‹¬å­˜å‚¨è¿æ¥éªŒè¯ã€é…ç½®æ£€æŸ¥ã€ç¯å¢ƒå‡†å¤‡",
      "code": "// ç»ˆæå·¥ä½œæµç³»ç»Ÿåˆå§‹åŒ–èŠ‚ç‚¹
const axios = require('axios');

class SystemInitializer {
  constructor() {
    this.config = {
      storage_type: process.env.STORAGE_TYPE || 'github',
      batch_size: parseInt(process.env.BATCH_SIZE) || 100,
      max_concurrent: parseInt(process.env.MAX_CONCURRENT) || 5,
      retry_count: parseInt(process.env.RETRY_COUNT) || 3,
      timeout_seconds: parseInt(process.env.TIMEOUT_SECONDS) || 300,
      enable_deep_repair: process.env.ENABLE_DEEP_REPAIR === 'true',
      enable_auto_generation: process.env.ENABLE_AUTO_GENERATION === 'true',
      enable_batch_processing: process.env.ENABLE_BATCH_PROCESSING === 'true',
      log_level: process.env.LOG_LEVEL || 'info'
    };
  }

  async validateStorageConnections() {
    const results = {};
    
    // GitHubè¿æ¥éªŒè¯
    results.github = await this.validateGitHubConnection();
    
    // Supabaseè¿æ¥éªŒè¯
    results.supabase = await this.validateSupabaseConnection();
    
    // æœ¬åœ°PostgreSQLè¿æ¥éªŒè¯
    results.local_pg = await this.validateLocalPostgresConnection();
    
    // æ ¹æ®é€‰æ‹©çš„å­˜å‚¨ç±»å‹éªŒè¯å¯ç”¨æ€§
    const selectedStorage = this.config.storage_type;
    let storageAvailable = false;
    
    switch (selectedStorage) {
      case 'github':
        storageAvailable = results.github.connected;
        break;
      case 'supabase':
        storageAvailable = results.supabase.connected;
        break;
      case 'local_pg':
        storageAvailable = results.local_pg.connected;
        break;
      case 'hybrid':
        storageAvailable = results.github.connected || results.supabase.connected || results.local_pg.connected;
        break;
      default:
        storageAvailable = results.github.connected || results.supabase.connected;
    }
    
    if (!storageAvailable) {
      throw new Error(`æ‰€é€‰å­˜å‚¨ç±»å‹ ${selectedStorage} ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®`);
    }
    
    return results;
  }

  async validateGitHubConnection() {
    try {
      if (!process.env.GITHUB_TOKEN || !process.env.GITHUB_REPO) {
        return { connected: false, error: 'GitHubç¯å¢ƒå˜é‡æœªé…ç½®' };
      }
      
      const response = await axios.get(
        `https://api.github.com/repos/${process.env.GITHUB_REPO}`,
        {
          headers: {
            'Authorization': `token ${process.env.GITHUB_TOKEN}`,
            'Accept': 'application/vnd.github.v3+json'
          },
          timeout: 10000
        }
      );
      
      // éªŒè¯ä»“åº“ç»“æ„
      await this.validateGitHubRepositoryStructure();
      
      return {
        connected: true,
        repo_info: response.data,
        timestamp: new Date().toISOString()
      };
    } catch (error) {
      return {
        connected: false,
        error: error.message,
        timestamp: new Date().toISOString()
      };
    }
  }

  async validateGitHubRepositoryStructure() {
    const requiredPaths = ['data/processed/', 'config/', 'logs/', 'templates/'];
    
    for (const path of requiredPaths) {
      try {
        await axios.get(
          `https://api.github.com/repos/${process.env.GITHUB_REPO}/contents/${path}`,
          {
            headers: {
              'Authorization': `token ${process.env.GITHUB_TOKEN}`
            }
          }
        );
      } catch (error) {
        // å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
        if (error.response?.status === 404) {
          await this.createGitHubDirectory(path);
        }
      }
    }
  }

  async createGitHubDirectory(path) {
    const placeholderContent = JSON.stringify({ 
      created_by: 'Coze Ultimate Workflow',
      created_at: new Date().toISOString(),
      purpose: 'Directory placeholder'
    }, null, 2);
    
    try {
      await axios.put(
        `https://api.github.com/repos/${process.env.GITHUB_REPO}/contents/${path}.gitkeep`,
        {
          message: `Create directory structure: ${path}`,
          content: Buffer.from(placeholderContent).toString('base64')
        },
        {
          headers: {
            'Authorization': `token ${process.env.GITHUB_TOKEN}`,
            'Accept': 'application/vnd.github.v3+json'
          }
        }
      );
    } catch (error) {
      console.warn(`æ— æ³•åˆ›å»ºç›®å½• ${path}:`, error.message);
    }
  }

  async validateSupabaseConnection() {
    try {
      if (!process.env.SUPABASE_URL || !process.env.SUPABASE_KEY) {
        return { connected: false, error: 'Supabaseç¯å¢ƒå˜é‡æœªé…ç½®' };
      }
      
      const { createClient } = require('@supabase/supabase-js');
      const supabase = createClient(
        process.env.SUPABASE_URL,
        process.env.SUPABASE_KEY
      );
      
      const { data, error } = await supabase
        .from('information_schema.tables')
        .select('table_name')
        .limit(1);
      
      if (error) throw error;
      
      return {
        connected: true,
        database_info: { tables_count: data?.length || 0 },
        timestamp: new Date().toISOString()
      };
    } catch (error) {
      return {
        connected: false,
        error: error.message,
        timestamp: new Date().toISOString()
      };
    }
  }

  async validateLocalPostgresConnection() {
    try {
      if (!process.env.LOCAL_PG_HOST || !process.env.LOCAL_PG_USER) {
        return { connected: false, error: 'æœ¬åœ°PostgreSQLç¯å¢ƒå˜é‡æœªé…ç½®' };
      }
      
      // ç”±äºCozeç¯å¢ƒé™åˆ¶ï¼Œæˆ‘ä»¬è¿›è¡ŒåŸºæœ¬çš„è¿æ¥æ£€æŸ¥
      const connectionConfig = {
        host: process.env.LOCAL_PG_HOST,
        port: process.env.LOCAL_PG_PORT || 5432,
        database: process.env.LOCAL_PG_DATABASE || 'postgres',
        user: process.env.LOCAL_PG_USER,
        password: process.env.LOCAL_PG_PASSWORD
      };
      
      console.log('æœ¬åœ°PostgreSQLè¿æ¥é…ç½®éªŒè¯å®Œæˆ:', {
        host: connectionConfig.host,
        port: connectionConfig.port,
        database: connectionConfig.database,
        user: connectionConfig.user
      });
      
      return {
        connected: true,
        config: connectionConfig,
        note: 'å®é™…è¿æ¥æµ‹è¯•éœ€è¦åœ¨æœ‰pgæ¨¡å—çš„ç¯å¢ƒä¸­è¿›è¡Œ',
        timestamp: new Date().toISOString()
      };
    } catch (error) {
      return {
        connected: false,
        error: error.message,
        timestamp: new Date().toISOString()
      };
    }
  }

  async validateConfiguration() {
    const errors = [];
    const warnings = [];
    
    // éªŒè¯æ‰¹å¤„ç†é…ç½®
    if (this.config.batch_size < 1 || this.config.batch_size > 10000) {
      errors.push('BATCH_SIZEå¿…é¡»åœ¨1-10000ä¹‹é—´');
    }
    
    if (this.config.max_concurrent < 1 || this.config.max_concurrent > 20) {
      errors.push('MAX_CONCURRENTå¿…é¡»åœ¨1-20ä¹‹é—´');
    }
    
    if (this.config.retry_count < 0 || this.config.retry_count > 10) {
      errors.push('RETRY_COUNTå¿…é¡»åœ¨0-10ä¹‹é—´');
    }
    
    // éªŒè¯æ—¥å¿—çº§åˆ«
    const validLogLevels = ['debug', 'info', 'warn', 'error'];
    if (!validLogLevels.includes(this.config.log_level)) {
      errors.push('LOG_LEVELå¿…é¡»æ˜¯debugã€infoã€warnæˆ–error');
    }
    
    // éªŒè¯å­˜å‚¨ç±»å‹
    const validStorageTypes = ['github', 'supabase', 'local_pg', 'hybrid'];
    if (!validStorageTypes.includes(this.config.storage_type)) {
      errors.push('STORAGE_TYPEå¿…é¡»æ˜¯githubã€supabaseã€local_pgæˆ–hybrid');
    }
    
    return { errors, warnings };
  }

  async setupMonitoring() {
    const monitoringConfig = {
      enabled: !!process.env.MONITORING_ENDPOINT,
      endpoint: process.env.MONITORING_ENDPOINT,
      metrics: ['execution_time', 'success_rate', 'error_count', 'data_volume'],
      alerts: {
        high_error_rate: 0.1, // 10%é”™è¯¯ç‡è§¦å‘å‘Šè­¦
        long_execution_time: 300, // 5åˆ†é’Ÿæ‰§è¡Œæ—¶é—´è§¦å‘å‘Šè­¦
        low_success_rate: 0.8 // 80%æˆåŠŸç‡è§¦å‘å‘Šè­¦
      }
    };
    
    return monitoringConfig;
  }

  async logInitialization(storageResults, configValidation, monitoringConfig) {
    const logEntry = {
      timestamp: new Date().toISOString(),
      level: 'info',
      component: 'system_initializer',
      message: 'ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ',
      storage_connections: storageResults,
      config_validation: configValidation,
      monitoring_config: monitoringConfig,
      system_config: this.config,
      version: '2.0',
      workflow_id: `workflow_${Date.now()}`
    };
    
    console.log('ç³»ç»Ÿåˆå§‹åŒ–æ—¥å¿—:', JSON.stringify(logEntry, null, 2));
    
    // å­˜å‚¨åˆå§‹åŒ–æ—¥å¿—
    await this.storeInitializationLog(logEntry);
    
    return logEntry;
  }

  async storeInitializationLog(logEntry) {
    try {
      const storageType = process.env.STORAGE_TYPE || 'github';
      
      switch (storageType) {
        case 'github':
          await this.storeLogToGitHub(logEntry);
          break;
        case 'supabase':
          await this.storeLogToSupabase(logEntry);
          break;
        case 'local_pg':
          await this.storeLogToLocalPostgres(logEntry);
          break;
      }
    } catch (error) {
      console.error('å­˜å‚¨åˆå§‹åŒ–æ—¥å¿—å¤±è´¥:', error.message);
    }
  }

  async storeLogToGitHub(logEntry) {
    if (!process.env.GITHUB_TOKEN || !process.env.GITHUB_REPO) return;
    
    try {
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      const filePath = `logs/initialization/${timestamp}.json`;
      
      await axios.put(
        `https://api.github.com/repos/${process.env.GITHUB_REPO}/contents/${filePath}`,
        {
          message: `Store initialization log: ${timestamp}`,
          content: Buffer.from(JSON.stringify(logEntry, null, 2)).toString('base64')
        },
        {
          headers: {
            'Authorization': `token ${process.env.GITHUB_TOKEN}`,
            'Accept': 'application/vnd.github.v3+json'
          }
        }
      );
    } catch (error) {
      console.error('GitHubæ—¥å¿—å­˜å‚¨å¤±è´¥:', error.message);
    }
  }

  async storeLogToSupabase(logEntry) {
    if (!process.env.SUPABASE_URL || !process.env.SUPABASE_KEY) return;
    
    try {
      const { createClient } = require('@supabase/supabase-js');
      const supabase = createClient(
        process.env.SUPABASE_URL,
        process.env.SUPABASE_KEY
      );
      
      await supabase.from('system_logs').insert({
        level: logEntry.level,
        component: logEntry.component,
        message: logEntry.message,
        data: logEntry,
        timestamp: logEntry.timestamp
      });
    } catch (error) {
      console.error('Supabaseæ—¥å¿—å­˜å‚¨å¤±è´¥:', error.message);
    }
  }

  async storeLogToLocalPostgres(logEntry) {
    if (!process.env.LOCAL_PG_HOST || !process.env.LOCAL_PG_USER) return;
    
    console.log('æœ¬åœ°PostgreSQLæ—¥å¿—å­˜å‚¨:', logEntry.message);
    // å®é™…å®ç°éœ€è¦pgæ¨¡å—
  }
}

async function main() {
  const initializer = new SystemInitializer();
  
  console.log('ğŸš€ å¼€å§‹ç³»ç»Ÿåˆå§‹åŒ–...');
  
  try {
    // éªŒè¯å­˜å‚¨è¿æ¥
    const storageResults = await initializer.validateStorageConnections();
    console.log('å­˜å‚¨è¿æ¥éªŒè¯å®Œæˆ:', storageResults);
    
    // éªŒè¯é…ç½®
    const configValidation = await initializer.validateConfiguration();
    if (configValidation.errors.length > 0) {
      throw new Error(`é…ç½®éªŒè¯å¤±è´¥: ${configValidation.errors.join(', ')}`);
    }
    
    // è®¾ç½®ç›‘æ§
    const monitoringConfig = await initializer.setupMonitoring();
    
    // è®°å½•åˆå§‹åŒ–æ—¥å¿—
    const logEntry = await initializer.logInitialization(storageResults, configValidation, monitoringConfig);
    
    console.log('âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ');
    
    return {
      initialization_successful: true,
      storage_results: storageResults,
      config_validation: configValidation,
      monitoring_config: monitoringConfig,
      system_config: initializer.config,
      workflow_id: logEntry.workflow_id,
      timestamp: new Date().toISOString()
    };
    
  } catch (error) {
    console.error('âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥:', error.message);
    
    // è®°å½•é”™è¯¯æ—¥å¿—
    await initializer.logInitialization({
      timestamp: new Date().toISOString(),
      level: 'error',
      component: 'system_initializer',
      message: 'ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥',
      error: error.message,
      stack: error.stack
    }, { errors: [error.message], warnings: [] }, {});
    
    throw error;
  }
}

main();",
      "inputs": [],
      "outputs": [
        "initialization_successful",
        "storage_results",
        "config_validation",
        "monitoring_config",
        "system_config",
        "workflow_id",
        "timestamp"
      ]
    },
    {
      "id": "2",
      "name": "ğŸ” æ™ºèƒ½å¢é‡æ•°æ®å‘ç°å™¨",
      "type": "javascript",
      "description": "æ™ºèƒ½å‘ç°å’Œè·å–å¢é‡æ•°æ®ï¼Œæ”¯æŒå¤šç§æ•°æ®æºå’Œå¢é‡æ£€æµ‹ç­–ç•¥",
      "code": "// æ™ºèƒ½å¢é‡æ•°æ®å‘ç°å™¨èŠ‚ç‚¹
const axios = require('axios');

class SmartIncrementalDataDiscoverer {
  constructor(config) {
    this.config = config;
    this.discoveryStrategies = {
      timestamp: new TimestampDiscovery(),
      hash: new HashDiscovery(),
      version: new VersionDiscovery(),
      content: new ContentDiscovery()
    };
  }

  async discoverIncrementalData(lastProcessedAt, workflowId) {
    const dataSources = JSON.parse(process.env.DATA_SOURCES || '[]');
    const discoveredData = [];
    const discoveryMetrics = [];
    
    for (const sourceConfig of dataSources) {
      try {
        console.log(`æ­£åœ¨å‘ç°æ•°æ®æº: ${sourceConfig.type}`, sourceConfig.config);
        
        const startTime = Date.now();
        const data = await this.discoverFromSource(sourceConfig, lastProcessedAt);
        const endTime = Date.now();
        
        discoveredData.push(...data.items);
        discoveryMetrics.push({
          source_type: sourceConfig.type,
          source_config: sourceConfig.config,
          discovered_count: data.items.length,
          incremental_count: data.incremental_count,
          duplicate_count: data.duplicate_count,
          discovery_time_ms: endTime - startTime,
          strategy_used: data.strategy_used,
          confidence_score: data.confidence_score
        });
        
      } catch (error) {
        console.error(`æ•°æ®æºå‘ç°å¤±è´¥: ${sourceConfig.type}`, error.message);
        discoveryMetrics.push({
          source_type: sourceConfig.type,
          source_config: sourceConfig.config,
          discovered_count: 0,
          incremental_count: 0,
          duplicate_count: 0,
          discovery_time_ms: Date.now() - startTime,
          error: error.message,
          confidence_score: 0
        });
      }
    }
    
    // æ•°æ®å»é‡å’Œåˆå¹¶
    const deduplicatedData = await this.deduplicateData(discoveredData);
    
    // æ•°æ®è´¨é‡è¯„ä¼°
    const qualityAssessment = await this.assessDataQuality(deduplicatedData);
    
    return {
      discovered_data: deduplicatedData,
      discovery_metrics: discoveryMetrics,
      total_discovered: discoveredData.length,
      total_incremental: deduplicatedData.length,
      quality_assessment: qualityAssessment,
      discovery_timestamp: new Date().toISOString(),
      workflow_id: workflowId
    };
  }

  async discoverFromSource(sourceConfig, lastProcessedAt) {
    const discoverer = this.createDiscoverer(sourceConfig.type);
    return await discoverer.discover(sourceConfig.config, lastProcessedAt);
  }

  createDiscoverer(type) {
    switch (type) {
      case 'api':
        return new APIDataDiscoverer(this.discoveryStrategies);
      case 'database':
        return new DatabaseDataDiscoverer(this.discoveryStrategies);
      case 'web':
        return new WebDataDiscoverer(this.discoveryStrategies);
      case 'file':
        return new FileDataDiscoverer(this.discoveryStrategies);
      case 'stream':
        return new StreamDataDiscoverer(this.discoveryStrategies);
      default:
        throw new Error(`ä¸æ”¯æŒçš„æ•°æ®æºç±»å‹: ${type}`);
    }
  }

  async deduplicateData(data) {
    const seen = new Set();
    const deduplicated = [];
    const duplicates = [];
    
    for (const item of data) {
      const hash = this.generateDataHash(item);
      
      if (!seen.has(hash)) {
        seen.add(hash);
        deduplicated.push({
          ...item,
          _deduplication: {
            hash: hash,
            is_duplicate: false,
            original_index: deduplicated.length
          }
        });
      } else {
        duplicates.push({
          ...item,
          _deduplication: {
            hash: hash,
            is_duplicate: true,
            original_index: -1
          }
        });
      }
    }
    
    return {
      items: deduplicated,
      duplicates: duplicates,
      deduplication_rate: (duplicates.length / data.length) * 100,
      unique_count: deduplicated.length
    };
  }

  generateDataHash(item) {
    const content = JSON.stringify(item, Object.keys(item).sort());
    return require('crypto').createHash('sha256').update(content).digest('hex');
  }

  async assessDataQuality(data) {
    const assessment = {
      completeness: this.assessCompleteness(data),
      consistency: this.assessConsistency(data),
      accuracy: this.assessAccuracy(data),
      timeliness: this.assessTimeliness(data),
      validity: this.assessValidity(data),
      uniqueness: this.assessUniqueness(data)
    };
    
    assessment.overall_score = Object.values(assessment).reduce((sum, metric) => sum + metric.score, 0) / Object.keys(assessment).length;
    
    return assessment;
  }

  assessCompleteness(data) {
    const totalFields = data.reduce((sum, item) => sum + Object.keys(item).length, 0);
    const nonNullFields = data.reduce((sum, item) => {
      return sum + Object.values(item).filter(value => value !== null && value !== undefined && value !== '').length;
    }, 0);
    
    const score = (nonNullFields / totalFields) * 100;
    
    return {
      score: score,
      completeness_rate: score,
      missing_fields_count: totalFields - nonNullFields
    };
  }

  assessConsistency(data) {
    // ç®€åŒ–çš„æ•°æ®ä¸€è‡´æ€§è¯„ä¼°
    const dataTypes = {};
    let consistentCount = 0;
    
    data.forEach(item => {
      Object.entries(item).forEach(([key, value]) => {
        if (!dataTypes[key]) {
          dataTypes[key] = typeof value;
        } else if (dataTypes[key] === typeof value) {
          consistentCount++;
        }
      });
    });
    
    const score = (consistentCount / (data.length * Object.keys(dataTypes).length)) * 100;
    
    return {
      score: score,
      consistency_rate: score,
      data_types: dataTypes
    };
  }

  assessAccuracy(data) {
    // ç®€åŒ–çš„æ•°æ®å‡†ç¡®æ€§è¯„ä¼°
    let accurateCount = 0;
    
    data.forEach(item => {
      // æ£€æŸ¥é‚®ç®±æ ¼å¼
      if (item.email && /^[^\s@]+@[^\s@]+\.[^\s@]+$/.test(item.email)) {
        accurateCount++;
      }
      
      // æ£€æŸ¥æ—¥æœŸæ ¼å¼
      if (item.created_at && !isNaN(Date.parse(item.created_at))) {
        accurateCount++;
      }
      
      // æ£€æŸ¥æ•°å­—èŒƒå›´
      if (item.age && typeof item.age === 'number' && item.age > 0 && item.age < 150) {
        accurateCount++;
      }
    });
    
    const score = (accurateCount / (data.length * 3)) * 100;
    
    return {
      score: score,
      accuracy_rate: score,
      validation_checks: ['email_format', 'date_format', 'number_range']
    };
  }

  assessTimeliness(data) {
    const now = new Date();
    const recentCount = data.filter(item => {
      const createdAt = new Date(item.created_at || item.updated_at || item.timestamp);
      const daysDiff = (now - createdAt) / (1000 * 60 * 60 * 24);
      return daysDiff <= 7; // 7å¤©å†…ä¸ºåŠæ—¶æ•°æ®
    }).length;
    
    const score = (recentCount / data.length) * 100;
    
    return {
      score: score,
      timeliness_rate: score,
      recent_data_count: recentCount
    };
  }

  assessValidity(data) {
    // æ£€æŸ¥æ•°æ®æ ¼å¼å’Œçº¦æŸ
    let validCount = 0;
    
    data.forEach(item => {
      let isValid = true;
      
      // å¿…å¡«å­—æ®µæ£€æŸ¥
      const requiredFields = ['id', 'name']; // ç¤ºä¾‹å¿…å¡«å­—æ®µ
      for (const field of requiredFields) {
        if (!item[field]) {
          isValid = false;
          break;
        }
      }
      
      if (isValid) validCount++;
    });
    
    const score = (validCount / data.length) * 100;
    
    return {
      score: score,
      validity_rate: score,
      valid_records_count: validCount
    };
  }

  assessUniqueness(data) {
    const uniqueHashes = new Set(data.map(item => this.generateDataHash(item)));
    const uniquenessRate = (uniqueHashes.size / data.length) * 100;
    
    return {
      score: uniquenessRate,
      uniqueness_rate: uniquenessRate,
      unique_records_count: uniqueHashes.size
    };
  }
}

// åŸºç¡€å‘ç°ç­–ç•¥ç±»
class DiscoveryStrategy {
  constructor(name) {
    this.name = name;
  }
  
  async detectIncremental(items, lastProcessedAt) {
    throw new Error('å­ç±»å¿…é¡»å®ç°detectIncrementalæ–¹æ³•');
  }
}

class TimestampDiscovery extends DiscoveryStrategy {
  constructor() {
    super('timestamp');
  }
  
  async detectIncremental(items, lastProcessedAt) {
    const incremental = items.filter(item => {
      const itemTimestamp = new Date(item.created_at || item.updated_at || item.timestamp);
      const lastProcessed = new Date(lastProcessedAt);
      return itemTimestamp > lastProcessed;
    });
    
    return {
      incremental: incremental,
      strategy: this.name,
      confidence: 0.95,
      incremental_count: incremental.length
    };
  }
}

class HashDiscovery extends DiscoveryStrategy {
  constructor() {
    super('hash');
  }
  
  async detectIncremental(items, lastProcessedAt) {
    // åŸºäºå†…å®¹å“ˆå¸Œçš„å¢é‡æ£€æµ‹
    const hashes = new Set();
    const incremental = [];
    
    for (const item of items) {
      const hash = require('crypto').createHash('sha256')
        .update(JSON.stringify(item)).digest('hex');
      
      if (!hashes.has(hash)) {
        hashes.add(hash);
        incremental.push({
          ...item,
          _discovery_hash: hash
        });
      }
    }
    
    return {
      incremental: incremental,
      strategy: this.name,
      confidence: 0.9,
      incremental_count: incremental.length
    };
  }
}

class VersionDiscovery extends DiscoveryStrategy {
  constructor() {
    super('version');
  }
  
  async detectIncremental(items, lastProcessedAt) {
    const incremental = items.filter(item => {
      const currentVersion = item.version || item._version || 0;
      const lastVersion = parseInt(lastProcessedAt) || 0;
      return currentVersion > lastVersion;
    });
    
    return {
      incremental: incremental,
      strategy: this.name,
      confidence: 0.85,
      incremental_count: incremental.length
    };
  }
}

class ContentDiscovery extends DiscoveryStrategy {
  constructor() {
    super('content');
  }
  
  async detectIncremental(items, lastProcessedAt) {
    // åŸºäºå†…å®¹å˜åŒ–çš„å¢é‡æ£€æµ‹
    const incremental = items.filter(item => {
      // æ£€æŸ¥å…³é”®å­—æ®µæ˜¯å¦å‘ç”Ÿå˜åŒ–
      const contentFields = ['content', 'data', 'payload', 'body'];
      return contentFields.some(field => {
        const fieldValue = item[field];
        return fieldValue && typeof fieldValue === 'string' && fieldValue.length > 0;
      });
    });
    
    return {
      incremental: incremental,
      strategy: this.name,
      confidence: 0.8,
      incremental_count: incremental.length
    };
  }
}

// å…·ä½“æ•°æ®æºå‘ç°å™¨
class APIDataDiscoverer {
  constructor(strategies) {
    this.strategies = strategies;
  }
  
  async discover(config, lastProcessedAt) {
    const response = await axios.get(config.url, {
      params: {
        last_updated: lastProcessedAt,
        limit: process.env.BATCH_SIZE || 100,
        ...config.params
      },
      headers: config.headers || {},
      timeout: 30000
    });
    
    const items = Array.isArray(response.data) ? response.data : [response.data];
    
    // åº”ç”¨å¤šç§å¢é‡æ£€æµ‹ç­–ç•¥
    const strategyResults = await Promise.all(
      Object.values(this.strategies).map(strategy => 
        strategy.detectIncremental(items, lastProcessedAt)
      )
    );
    
    // é€‰æ‹©æœ€ä½³ç­–ç•¥ç»“æœ
    const bestStrategy = strategyResults.reduce((best, current) => 
      current.confidence > best.confidence ? current : best
    );
    
    return {
      items: bestStrategy.incremental,
      incremental_count: bestStrategy.incremental_count,
      duplicate_count: items.length - bestStrategy.incremental_count,
      strategy_used: bestStrategy.strategy,
      confidence_score: bestStrategy.confidence
    };
  }
}

class DatabaseDataDiscoverer {
  constructor(strategies) {
    this.strategies = strategies;
  }
  
  async discover(config, lastProcessedAt) {
    const { createClient } = require('@supabase/supabase-js');
    const supabase = createClient(
      process.env.SUPABASE_URL,
      process.env.SUPABASE_KEY
    );
    
    const { data, error } = await supabase
      .from(config.table)
      .select('*')
      .gt(config.incremental_field || 'updated_at', lastProcessedAt)
      .limit(process.env.BATCH_SIZE || 100);
    
    if (error) throw error;
    
    const items = data || [];
    
    const strategyResults = await Promise.all(
      Object.values(this.strategies).map(strategy => 
        strategy.detectIncremental(items, lastProcessedAt)
      )
    );
    
    const bestStrategy = strategyResults.reduce((best, current) => 
      current.confidence > best.confidence ? current : best
    );
    
    return {
      items: bestStrategy.incremental,
      incremental_count: bestStrategy.incremental_count,
      duplicate_count: items.length - bestStrategy.incremental_count,
      strategy_used: bestStrategy.strategy,
      confidence_score: bestStrategy.confidence
    };
  }
}

class WebDataDiscoverer {
  constructor(strategies) {
    this.strategies = strategies;
  }
  
  async discover(config, lastProcessedAt) {
    const response = await axios.get(config.url, {
      timeout: 30000,
      headers: {
        'User-Agent': 'Coze-Ultimate-Workflow/2.0'
      }
    });
    
    // ç®€åŒ–çš„ç½‘é¡µæ•°æ®æå–
    const items = [{
      content: response.data,
      scraped_at: new Date().toISOString(),
      url: config.url,
      status_code: response.status
    }];
    
    const strategyResults = await Promise.all(
      Object.values(this.strategies).map(strategy => 
        strategy.detectIncremental(items, lastProcessedAt)
      )
    );
    
    const bestStrategy = strategyResults.reduce((best, current) => 
      current.confidence > best.confidence ? current : best
    );
    
    return {
      items: bestStrategy.incremental,
      incremental_count: bestStrategy.incremental_count,
      duplicate_count: items.length - bestStrategy.incremental_count,
      strategy_used: bestStrategy.strategy,
      confidence_score: bestStrategy.confidence
    };
  }
}

class FileDataDiscoverer {
  constructor(strategies) {
    this.strategies = strategies;
  }
  
  async discover(config, lastProcessedAt) {
    // æ–‡ä»¶æ•°æ®å‘ç°ï¼ˆéœ€è¦æ–‡ä»¶ç³»ç»Ÿè®¿é—®ï¼‰
    const items = [];
    
    // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…å®ç°éœ€è¦æ–‡ä»¶ç³»ç»Ÿè®¿é—®
    console.log('æ–‡ä»¶æ•°æ®æºå‘ç°:', config);
    
    return {
      items: items,
      incremental_count: items.length,
      duplicate_count: 0,
      strategy_used: 'file',
      confidence_score: 0.7
    };
  }
}

class StreamDataDiscoverer {
  constructor(strategies) {
    this.strategies = strategies;
  }
  
  async discover(config, lastProcessedAt) {
    // æµæ•°æ®å‘ç°
    const items = [];
    
    // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…å®ç°éœ€è¦æµå¤„ç†æ”¯æŒ
    console.log('æµæ•°æ®æºå‘ç°:', config);
    
    return {
      items: items,
      incremental_count: items.length,
      duplicate_count: 0,
      strategy_used: 'stream',
      confidence_score: 0.6
    };
  }
}

async function main(input) {
  const discoverer = new SmartIncrementalDataDiscoverer();
  
  try {
    const result = await discoverer.discoverIncrementalData(
      input.last_processed_at,
      input.workflow_id
    );
    
    console.log('æ™ºèƒ½å¢é‡æ•°æ®å‘ç°å®Œæˆ:', {
      total_discovered: result.total_discovered,
      total_incremental: result.total_incremental,
      quality_score: result.quality_assessment.overall_score
    });
    
    return result;
    
  } catch (error) {
    console.error('å¢é‡æ•°æ®å‘ç°å¤±è´¥:', error.message);
    
    return {
      discovered_data: [],
      discovery_metrics: [],
      total_discovered: 0,
      total_incremental: 0,
      quality_assessment: { overall_score: 0 },
      discovery_timestamp: new Date().toISOString(),
      workflow_id: input.workflow_id,
      error: error.message
    };
  }
}

main(input);",
      "inputs": [
        "last_processed_at",
        "workflow_id"
      ],
      "outputs": [
        "discovered_data",
        "discovery_metrics",
        "total_discovered",
        "total_incremental",
        "quality_assessment",
        "discovery_timestamp",
        "workflow_id"
      ]
    },
    {
      "id": "3",
      "name": "âš™ï¸ é«˜çº§æ•°æ®å¤„ç†å¼•æ“",
      "type": "javascript",
      "description": "é«˜çº§æ•°æ®å¤„ç†å¼•æ“ï¼ŒåŒ…å«æ¸…æ´—ã€éªŒè¯ã€è½¬æ¢ã€å¢å¼ºç­‰å®Œæ•´åŠŸèƒ½",
      "code": "// é«˜çº§æ•°æ®å¤„ç†å¼•æ“èŠ‚ç‚¹
const axios = require('axios');

class AdvancedDataProcessingEngine {
  constructor(config) {
    this.config = config;
    this.processors = {
      cleaner: new DataCleaner(),
      validator: new DataValidator(),
      transformer: new DataTransformer(),
      enhancer: new DataEnhancer(),
      normalizer: new DataNormalizer(),
      enricher: new DataEnricher()
    };
  }

  async processBatch(data, metrics) {
    const processingResults = [];
    const processingErrors = [];
    const processingMetrics = [];
    
    const batchSize = parseInt(process.env.BATCH_SIZE) || 100;
    const maxConcurrent = parseInt(process.env.MAX_CONCURRENT) || 5;
    
    console.log(`å¼€å§‹å¤„ç† ${data.length} æ¡æ•°æ®ï¼Œæ‰¹é‡å¤§å°: ${batchSize}, æœ€å¤§å¹¶å‘: ${maxConcurrent}`);
    
    // åˆ†æ‰¹å¤„ç†æ•°æ®
    for (let i = 0; i < data.length; i += batchSize) {
      const batch = data.slice(i, i + batchSize);
      console.log(`å¤„ç†æ‰¹æ¬¡ ${Math.floor(i / batchSize) + 1}/${Math.ceil(data.length / batchSize)}`);
      
      try {
        const batchResult = await this.processBatchConcurrent(batch, maxConcurrent);
        processingResults.push(...batchResult.processed);
        processingErrors.push(...batchResult.errors);
        processingMetrics.push({
          batch_index: Math.floor(i / batchSize),
          batch_size: batch.length,
          processed_count: batchResult.processed.length,
          error_count: batchResult.errors.length,
          processing_time_ms: batchResult.processing_time,
          memory_usage_mb: batchResult.memory_usage
        });
      } catch (error) {
        console.error(`æ‰¹æ¬¡å¤„ç†å¤±è´¥:`, error.message);
        processingErrors.push({
          batch_index: Math.floor(i / batchSize),
          error: error.message,
          stack: error.stack
        });
      }
      
      // æ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œé¿å…è¿‡è½½
      if (i + batchSize < data.length) {
        await this.delay(1000);
      }
    }
    
    // ç”Ÿæˆå¤„ç†æŠ¥å‘Š
    const processingReport = this.generateProcessingReport(
      processingResults,
      processingErrors,
      processingMetrics,
      metrics
    );
    
    return {
      processed_data: processingResults,
      processing_errors: processingErrors,
      processing_metrics: processingMetrics,
      processing_report: processingReport,
      success_count: processingResults.length,
      error_count: processingErrors.length,
      success_rate: (processingResults.length / data.length) * 100,
      batch_id: `batch_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      processing_timestamp: new Date().toISOString()
    };
  }

  async processBatchConcurrent(batch, maxConcurrent) {
    const startTime = Date.now();
    const processed = [];
    const errors = [];
    
    // å°†æ‰¹æ¬¡åˆ†æˆæ›´å°çš„å¹¶å‘ç»„
    const concurrentGroups = this.createConcurrentGroups(batch, maxConcurrent);
    
    for (const group of concurrentGroups) {
      const groupPromises = group.map(item => this.processItem(item));
      const groupResults = await Promise.allSettled(groupPromises);
      
      groupResults.forEach((result, index) => {
        if (result.status === 'fulfilled') {
          processed.push(result.value);
        } else {
          errors.push({
            item: group[index],
            error: result.reason.message,
            stack: result.reason.stack
          });
        }
      });
    }
    
    const endTime = Date.now();
    const processingTime = endTime - startTime;
    
    // ä¼°ç®—å†…å­˜ä½¿ç”¨ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
    const memoryUsage = this.estimateMemoryUsage(processed, errors);
    
    return {
      processed: processed,
      errors: errors,
      processing_time: processingTime,
      memory_usage: memoryUsage
    };
  }

  createConcurrentGroups(batch, maxConcurrent) {
    const groups = [];
    for (let i = 0; i < batch.length; i += maxConcurrent) {
      groups.push(batch.slice(i, i + maxConcurrent));
    }
    return groups;
  }

  async processItem(item) {
    try {
      let processedItem = { ...item };
      
      // 1. æ•°æ®æ¸…æ´—
      processedItem = await this.processors.cleaner.clean(processedItem);
      
      // 2. æ•°æ®éªŒè¯
      const validationResult = await this.processors.validator.validate(processedItem);
      if (!validationResult.isValid) {
        throw new Error(`æ•°æ®éªŒè¯å¤±è´¥: ${validationResult.errors.join(', ')}`);
      }
      
      // 3. æ•°æ®è½¬æ¢
      processedItem = await this.processors.transformer.transform(processedItem);
      
      // 4. æ•°æ®å¢å¼º
      processedItem = await this.processors.enhancer.enhance(processedItem);
      
      // 5. æ•°æ®è§„èŒƒåŒ–
      processedItem = await this.processors.normalizer.normalize(processedItem);
      
      // 6. æ•°æ®ä¸°å¯Œ
      processedItem = await this.processors.enricher.enrich(processedItem);
      
      // æ·»åŠ å¤„ç†å…ƒæ•°æ®
      processedItem._processing = {
        processed_at: new Date().toISOString(),
        processors_applied: Object.keys(this.processors),
        validation_passed: validationResult.isValid,
        processing_version: '2.0'
      };
      
      return processedItem;
      
    } catch (error) {
      // é”™è¯¯å¤„ç†å’Œæ•°æ®æ¢å¤
      const recoveredItem = await this.attemptDataRecovery(item, error);
      
      if (recoveredItem) {
        return recoveredItem;
      } else {
        throw error;
      }
    }
  }

  async attemptDataRecovery(item, error) {
    console.log('å°è¯•æ•°æ®æ¢å¤:', error.message);
    
    try {
      // ç®€åŒ–çš„æ•°æ®æ¢å¤ç­–ç•¥
      const recoveredItem = {
        ...item,
        _recovery: {
          original_error: error.message,
          recovery_attempted: true,
          recovery_timestamp: new Date().toISOString(),
          recovery_strategy: 'partial_recovery'
        }
      };
      
      // åº”ç”¨åŸºæœ¬çš„æ¸…æ´—å’ŒéªŒè¯
      recoveredItem = await this.processors.cleaner.clean(recoveredItem);
      const validationResult = await this.processors.validator.validate(recoveredItem);
      
      if (validationResult.isValid) {
        return recoveredItem;
      }
      
      return null;
      
    } catch (recoveryError) {
      console.error('æ•°æ®æ¢å¤å¤±è´¥:', recoveryError.message);
      return null;
    }
  }

  generateProcessingReport(processed, errors, metrics, originalMetrics) {
    const report = {
      summary: {
        total_processed: processed.length + errors.length,
        successful: processed.length,
        failed: errors.length,
        success_rate: (processed.length / (processed.length + errors.length)) * 100
      },
      quality_metrics: this.calculateQualityMetrics(processed),
      performance_metrics: this.calculatePerformanceMetrics(metrics),
      error_analysis: this.analyzeErrors(errors),
      data_insights: this.generateDataInsights(processed),
      recommendations: this.generateRecommendations(processed, errors, metrics),
      timestamp: new Date().toISOString()
    };
    
    return report;
  }

  calculateQualityMetrics(processed) {
    const qualityScores = processed.map(item => {
      return item._processing?.quality_score || this.calculateItemQualityScore(item);
    });
    
    return {
      average_quality_score: qualityScores.reduce((sum, score) => sum + score, 0) / qualityScores.length,
      quality_score_distribution: this.calculateDistribution(qualityScores),
      quality_improvement_rate: this.calculateQualityImprovement(processed)
    };
  }

  calculateItemQualityScore(item) {
    let score = 100;
    
    // å®Œæ•´æ€§æ£€æŸ¥
    const nullFields = Object.values(item).filter(v => v === null || v === undefined).length;
    score -= (nullFields / Object.keys(item).length) * 20;
    
    // æ ¼å¼æ£€æŸ¥
    if (item.email && !/^[^\s@]+@[^\s@]+\.[^\s@]+$/.test(item.email)) {
      score -= 15;
    }
    
    // æ•°æ®ç±»å‹æ£€æŸ¥
    if (item.age && (typeof item.age !== 'number' || item.age < 0 || item.age > 150)) {
      score -= 10;
    }
    
    return Math.max(0, score);
  }

  calculatePerformanceMetrics(metrics) {
    const processingTimes = metrics.map(m => m.processing_time_ms);
    const memoryUsages = metrics.map(m => m.memory_usage_mb);
    
    return {
      average_processing_time_ms: processingTimes.reduce((sum, time) => sum + time, 0) / processingTimes.length,
      total_processing_time_ms: processingTimes.reduce((sum, time) => sum + time, 0),
      average_memory_usage_mb: memoryUsages.reduce((sum, memory) => sum + memory, 0) / memoryUsages.length,
      peak_memory_usage_mb: Math.max(...memoryUsages),
      throughput_items_per_second: this.calculateThroughput(metrics)
    };
  }

  calculateThroughput(metrics) {
    const totalItems = metrics.reduce((sum, m) => sum + m.processed_count, 0);
    const totalTime = metrics.reduce((sum, m) => sum + m.processing_time_ms, 0);
    return (totalItems / (totalTime / 1000)).toFixed(2);
  }

  analyzeErrors(errors) {
    const errorTypes = {};
    const errorMessages = {};
    
    errors.forEach(error => {
      const errorType = this.categorizeError(error);
      errorTypes[errorType] = (errorTypes[errorType] || 0) + 1;
      
      const errorMessage = error.error || 'Unknown error';
      errorMessages[errorMessage] = (errorMessages[errorMessage] || 0) + 1;
    });
    
    return {
      error_types: errorTypes,
      error_messages: errorMessages,
      most_common_error: Object.keys(errorMessages).reduce((a, b) => 
        errorMessages[a] > errorMessages[b] ? a : b, Object.keys(errorMessages)[0]
      ),
      error_rate: (errors.length / (errors.length + processed.length)) * 100
    };
  }

  categorizeError(error) {
    const errorMessage = error.error || '';
    
    if (errorMessage.includes('validation')) return 'validation_error';
    if (errorMessage.includes('network')) return 'network_error';
    if (errorMessage.includes('timeout')) return 'timeout_error';
    if (errorMessage.includes('format')) return 'format_error';
    if (errorMessage.includes('missing')) return 'missing_data_error';
    
    return 'unknown_error';
  }

  generateDataInsights(processed) {
    const insights = {
      data_volume: processed.length,
      field_coverage: this.calculateFieldCoverage(processed),
      data_patterns: this.identifyDataPatterns(processed),
      anomalies: this.detectAnomalies(processed),
      trends: this